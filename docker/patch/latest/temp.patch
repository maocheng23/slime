diff --git a/python/sglang/srt/distributed/communication_op.py b/python/sglang/srt/distributed/communication_op.py
index 95600ed..4d1b9c7 100644
--- a/python/sglang/srt/distributed/communication_op.py
+++ b/python/sglang/srt/distributed/communication_op.py
@@ -33,3 +33,9 @@ def broadcast_tensor_dict(
     if not torch.distributed.is_initialized():
         return tensor_dict
     return get_tp_group().broadcast_tensor_dict(tensor_dict, src)
+
+def tensor_model_parallel_tree_all_reduce(input_: torch.Tensor) -> torch.Tensor:
+    """Tree all-reduce the input tensor across model parallel group."""
+    from sglang.srt.tp_invariant_ops import tree_all_reduce_sum
+
+    return tree_all_reduce_sum(input_, device_group=get_tp_group().device_group)
\ No newline at end of file
diff --git a/python/sglang/srt/layers/communicator.py b/python/sglang/srt/layers/communicator.py
index 15df851..21a6b5f 100644
--- a/python/sglang/srt/layers/communicator.py
+++ b/python/sglang/srt/layers/communicator.py
@@ -25,6 +25,7 @@ from sglang.srt.distributed import (
     get_tensor_model_parallel_world_size,
     get_tp_group,
     tensor_model_parallel_all_reduce,
+    tensor_model_parallel_tree_all_reduce, 
 )
 from sglang.srt.distributed.device_communicators.pynccl_allocator import (
     use_symmetric_memory,
@@ -38,6 +39,7 @@ from sglang.srt.layers.dp_attention import (
     attn_tp_reduce_scatter_tensor,
     dp_gather_partial,
     dp_reduce_scatter_tensor,
+    dp_gather_replicate,
     dp_scatter,
     get_attention_dp_size,
     get_attention_tp_rank,
@@ -327,6 +329,7 @@ class LayerCommunicator:
         allow_reduce_scatter: bool = False,
         is_last_layer: bool = False,
         qkv_latent_func: Optional[Callable] = None,
+        layer_id: int = -1,  # Added for debug logging
     ):
         self.layer_scatter_modes = layer_scatter_modes
         self.input_layernorm = input_layernorm
@@ -334,6 +337,7 @@ class LayerCommunicator:
         self.allow_reduce_scatter = allow_reduce_scatter
         self.is_last_layer = is_last_layer
         self.qkv_latent_func = qkv_latent_func
+        self.layer_id = layer_id
 
         self._context = CommunicateContext.init_new()
         self._post_init_communicate()
@@ -519,8 +523,25 @@ class LayerCommunicator:
         forward_batch: ForwardBatch,
         cache=None,
     ):
+        import os
+        import logging
+        logger = logging.getLogger(__name__)
+        debug = os.environ.get('SLIME_DEBUG_LOGPROB_DIFF', '0') == '1'
+        
+        # Only print for layer 0
+        if debug and self.layer_id == 0:
+            logger.info(f"[SGLang prepare_mlp][Layer {self.layer_id}] "
+                  f"attn_tp_size={self._context.attn_tp_size}, "
+                  f"tp_size={self._context.tp_size}, "
+                  f"attn_dp_size={self._context.attn_dp_size}, "
+                  f"func={self._communicate_with_all_reduce_and_layer_norm_fn.__name__ if hasattr(self._communicate_with_all_reduce_and_layer_norm_fn, '__name__') else type(self._communicate_with_all_reduce_and_layer_norm_fn)}",
+                  flush=True)
+        
         if cache is not None:
             self._context.cache = cache
+        
+        # Pass layer_id to context for debug logging in static methods
+        self._context.layer_id = self.layer_id
 
         return self._communicate_with_all_reduce_and_layer_norm_fn(
             hidden_states=hidden_states,
@@ -692,6 +713,11 @@ class CommunicateWithAllReduceAndLayerNormFn:
         context: CommunicateContext,
     ):
 
+        import os
+        import logging
+        logger = logging.getLogger(__name__)
+        debug = os.environ.get('SLIME_DEBUG_LOGPROB_DIFF', '0') == '1'
+        
         if (
             context.is_same_group_size(
                 hidden_states_input_mode, hidden_states_output_mode
@@ -699,6 +725,10 @@ class CommunicateWithAllReduceAndLayerNormFn:
             and context.is_same_group_size(residual_input_mode, residual_output_mode)
             and context.attn_tp_size == 1
         ):
+            if debug:
+                logger.info(f"[SGLang CommunicateWithAllReduceAndLayerNormFn.get_fn] "
+                      f"Returning: _simple (NO all-reduce!) "
+                      f"attn_tp_size={context.attn_tp_size}", flush=True)
             return CommunicateWithAllReduceAndLayerNormFn._simple
 
         if (
@@ -709,6 +739,9 @@ class CommunicateWithAllReduceAndLayerNormFn:
             and (hidden_states_output_mode == ScatterMode.FULL)
             and (residual_output_mode == ScatterMode.TP_ATTN_FULL)
         ):
+            if debug:
+                logger.info(f"[SGLang CommunicateWithAllReduceAndLayerNormFn.get_fn] "
+                      f"Returning: _gather_hidden_states_and_residual (with all-reduce)", flush=True)
             return partial(
                 CommunicateWithAllReduceAndLayerNormFn._gather_hidden_states_and_residual,
                 residual_input_mode=residual_input_mode,
@@ -722,6 +755,9 @@ class CommunicateWithAllReduceAndLayerNormFn:
             and (hidden_states_output_mode == ScatterMode.SCATTERED)
             and (residual_output_mode == ScatterMode.SCATTERED)
         ):
+            if debug:
+                logger.info(f"[SGLang CommunicateWithAllReduceAndLayerNormFn.get_fn] "
+                      f"Returning: _scatter_hidden_states_and_residual (with reduce-scatter)", flush=True)
             return partial(
                 CommunicateWithAllReduceAndLayerNormFn._scatter_hidden_states_and_residual,
                 residual_input_mode=residual_input_mode,
@@ -793,6 +829,30 @@ class CommunicateWithAllReduceAndLayerNormFn:
                 if hidden_states.shape[0] != 0:
                     hidden_states = layernorm(hidden_states)
         else:
+            import os
+            import logging
+            _logger = logging.getLogger(__name__)
+            debug = os.environ.get('SLIME_DEBUG_LOGPROB_DIFF', '0') == '1'
+            pos = 0
+            tp_rank = context.tp_rank if hasattr(context, 'tp_rank') else 0
+            tp_size = context.tp_size if hasattr(context, 'tp_size') else 1
+            layer_id = getattr(context, 'layer_id', -1)
+            
+            # Only print for layer 0
+            should_print = debug and layer_id == 0 and hidden_states.shape[0] > 0
+            
+            # DEBUG: Before all-reduce
+            if should_print:
+                hs_val = hidden_states[pos, :5] if hidden_states.dim() == 2 else hidden_states[pos, 0, :5]
+                res_val = residual[pos, :5] if residual is not None and residual.dim() == 2 else (residual[pos, 0, :5] if residual is not None else None)
+                _logger.info(f"[communicator.py][_gather][TP {tp_rank}/{tp_size}][Layer {layer_id}] "
+                            f"BEFORE all-reduce: hidden_states[{pos},:5]: {hs_val.tolist()}")
+                _logger.info(f"[communicator.py][_gather][TP {tp_rank}/{tp_size}][Layer {layer_id}] "
+                            f"BEFORE all-reduce: hidden_states sum: {hidden_states[pos].float().sum().item():.6f}")
+                if res_val is not None:
+                    _logger.info(f"[communicator.py][_gather][TP {tp_rank}/{tp_size}][Layer {layer_id}] "
+                                f"residual[{pos},:5]: {res_val.tolist()}")
+            
             # According to the discussion in https://github.com/flashinfer-ai/flashinfer/issues/1223#issuecomment-3047256465
             # We set the max token num to 128 for allreduce fusion with min-latency case(use_oneshot=True).
             if (
@@ -802,14 +862,47 @@ class CommunicateWithAllReduceAndLayerNormFn:
                 and get_global_server_args().enable_flashinfer_allreduce_fusion
                 and hidden_states.shape[0] <= 2048
             ):
+                if should_print:
+                    _logger.info(f"[communicator.py][_gather][TP {tp_rank}/{tp_size}][Layer {layer_id}] "
+                                f"Using: forward_with_allreduce_fusion")
                 hidden_states, residual = layernorm.forward_with_allreduce_fusion(
                     hidden_states, residual
                 )
             else:
-                hidden_states = tensor_model_parallel_all_reduce(hidden_states)
+                rl_target = get_global_server_args().rl_on_policy_target
+                if rl_target == "fsdp_tp" or rl_target == "fsdp":
+                    if should_print:
+                        _logger.info(f"[communicator.py][_gather][TP {tp_rank}/{tp_size}][Layer {layer_id}] "
+                                    f"Using: tensor_model_parallel_tree_all_reduce (rl_target={rl_target})")
+                    hidden_states = tensor_model_parallel_tree_all_reduce(hidden_states)
+                else:
+                    if should_print:
+                        _logger.info(f"[communicator.py][_gather][TP {tp_rank}/{tp_size}][Layer {layer_id}] "
+                                    f"Using: tensor_model_parallel_all_reduce (NCCL)")
+                    hidden_states = tensor_model_parallel_all_reduce(hidden_states)
+                
+                # DEBUG: After all-reduce, before layernorm
+                if should_print:
+                    hs_val = hidden_states[pos, :5] if hidden_states.dim() == 2 else hidden_states[pos, 0, :5]
+                    _logger.info(f"[communicator.py][_gather][TP {tp_rank}/{tp_size}][Layer {layer_id}] "
+                                f"AFTER all-reduce (before LN): hidden_states[{pos},:5]: {hs_val.tolist()}")
+                    _logger.info(f"[communicator.py][_gather][TP {tp_rank}/{tp_size}][Layer {layer_id}] "
+                                f"AFTER all-reduce (before LN): hidden_states sum: {hidden_states[pos].float().sum().item():.6f}")
                 if _is_npu and context.cache is not None:
                     _ = prepare_weight_cache(hidden_states, context.cache)
                 hidden_states, residual = layernorm(hidden_states, residual)
+                
+                # DEBUG: After layernorm
+                if should_print:
+                    hs_val = hidden_states[pos, :5] if hidden_states.dim() == 2 else hidden_states[pos, 0, :5]
+                    res_val = residual[pos, :5] if residual is not None and residual.dim() == 2 else (residual[pos, 0, :5] if residual is not None else None)
+                    _logger.info(f"[communicator.py][_gather][TP {tp_rank}/{tp_size}][Layer {layer_id}] "
+                                f"AFTER layernorm: hidden_states[{pos},:5]: {hs_val.tolist()}")
+                    _logger.info(f"[communicator.py][_gather][TP {tp_rank}/{tp_size}][Layer {layer_id}] "
+                                f"AFTER layernorm: hidden_states sum: {hidden_states[pos].float().sum().item():.6f}")
+                    if res_val is not None:
+                        _logger.info(f"[communicator.py][_gather][TP {tp_rank}/{tp_size}][Layer {layer_id}] "
+                                    f"AFTER layernorm: residual[{pos},:5]: {res_val.tolist()}")
         return hidden_states, residual
 
     @staticmethod
diff --git a/python/sglang/srt/layers/linear.py b/python/sglang/srt/layers/linear.py
index 428f3a2..88da0b2 100644
--- a/python/sglang/srt/layers/linear.py
+++ b/python/sglang/srt/layers/linear.py
@@ -1417,7 +1417,14 @@ class RowParallelLinear(LinearBase):
             output_parallel = self.quant_method.apply(self, input_parallel, bias=bias_)
 
         if self.reduce_results and self.tp_size > 1 and not skip_all_reduce:
-            output = tensor_model_parallel_all_reduce(output_parallel)
+            # Use tree_all_reduce for true on-policy mode to match Megatron
+            from sglang.srt.server_args import get_global_server_args
+            server_args = get_global_server_args()
+            if server_args is not None and server_args.rl_on_policy_target in ("fsdp", "fsdp_tp"):
+                from sglang.srt.distributed import tensor_model_parallel_tree_all_reduce
+                output = tensor_model_parallel_tree_all_reduce(output_parallel)
+            else:
+                output = tensor_model_parallel_all_reduce(output_parallel)
         else:
             output = output_parallel
 
diff --git a/python/sglang/srt/layers/moe/fused_moe_triton/fused_moe.py b/python/sglang/srt/layers/moe/fused_moe_triton/fused_moe.py
index 14d6923..d6bcc33 100644
--- a/python/sglang/srt/layers/moe/fused_moe_triton/fused_moe.py
+++ b/python/sglang/srt/layers/moe/fused_moe_triton/fused_moe.py
@@ -8,7 +8,8 @@ from __future__ import annotations
 import functools
 import os
 from typing import TYPE_CHECKING, List, Optional
-
+from sglang.srt.tp_invariant_ops.tp_invariant_ops import moe_sum_tree_reduce
+from sglang.srt.server_args import get_global_server_args
 import torch
 import torch.nn.functional as F
 import triton.language as tl
@@ -320,7 +321,21 @@ def fused_experts_impl(
     gemm1_alpha: Optional[float] = None,
     gemm1_limit: Optional[float] = None,
     filter_expert: bool = True,
+    layer_id: Optional[int] = None,  # Optional layer_id for debugging
 ):
+    # import logging
+    # import os
+    # logger = logging.getLogger(__name__)
+    # logger.info(f"fused_experts_impl")
+    # logger.info(f"hidden_states.shape: {hidden_states.shape}, dtype: {hidden_states.dtype}")
+    # if hidden_states.shape[0] > 91:
+    #     logger.info(f"hidden_states[91, :5]: {hidden_states[91, :5].tolist()}")
+    # else:
+    #     logger.info(f"hidden_states[0, :5]: {hidden_states[0, :5].tolist()}")
+    # logger.info(f"w1.shape: {w1.shape}, dtype: {w1.dtype}")
+    # logger.info(f"w2.shape: {w2.shape}, dtype: {w2.dtype}")
+    # logger.info(f"topk_weights.shape: {topk_weights.shape}, dtype: {topk_weights.dtype}")
+    # logger.info(f"topk_ids.shape: {topk_ids.shape}, dtype: {topk_ids.dtype}")
     padded_size = padding_size
     if not (use_fp8_w8a8 or use_int8_w8a8) or block_shape is not None or _use_aiter:
         padded_size = 0
@@ -560,7 +575,10 @@ def fused_experts_impl(
 
         if routed_scaling_factor is None:
             routed_scaling_factor = 1.0
-
+        # import logging
+        # logger = logging.getLogger(__name__)
+        # logger.info(f"fused MOE RL on policy target: {get_global_server_args().rl_on_policy_target}")
+                
         if no_combine:
             pass
         elif _is_cuda:
@@ -572,6 +590,14 @@ def fused_experts_impl(
                     intermediate_cache3[:, 1],
                     out=out_hidden_states[begin_chunk_idx:end_chunk_idx],
                 ).squeeze(dim=1)
+            elif get_global_server_args().rl_on_policy_target and get_global_server_args().rl_on_policy_target == "fsdp_tp" or get_global_server_args().rl_on_policy_target == "fsdp":
+                moe_sum_tree_reduce(
+                    intermediate_cache3.view(*intermediate_cache3.shape),
+                    out_hidden_states[begin_chunk_idx:end_chunk_idx],
+                    curr_topk_ids,
+                    routed_scaling_factor,
+                    E,
+                )
             else:
                 # According to micro benchmark results, torch.compile can get better performance for small token.
                 if (
diff --git a/python/sglang/srt/layers/moe/fused_moe_triton/layer.py b/python/sglang/srt/layers/moe/fused_moe_triton/layer.py
index 8394635..379783b 100644
--- a/python/sglang/srt/layers/moe/fused_moe_triton/layer.py
+++ b/python/sglang/srt/layers/moe/fused_moe_triton/layer.py
@@ -67,7 +67,7 @@ from sglang.srt.utils import (
     next_power_of_2,
     round_up,
 )
-from sglang.srt.utils.custom_op import register_custom_op
+from sglang.srt.utils.common import direct_register_custom_op
 
 if is_flashinfer_available():
     from flashinfer import fp4_quantize
@@ -909,7 +909,7 @@ class FusedMoE(torch.nn.Module):
             assert TopKOutputChecker.format_is_standard(
                 topk_output
             ), "Only standard topk output is supported for piecewise cuda graph"
-            return moe_forward_piecewise_cuda_graph_impl(
+            return torch.ops.sglang.moe_forward_piecewise_cuda_graph_impl(
                 hidden_states,
                 topk_output.topk_weights,
                 topk_output.topk_ids,
@@ -923,6 +923,18 @@ class FusedMoE(torch.nn.Module):
         origin_hidden_states_dim = hidden_states.shape[-1]
         assert self.quant_method is not None
 
+        # Debug: compare expert input (SGLang side) - only print for layer 0
+        import os
+        if os.environ.get("DEBUG_SGLANG_EP_MAPPING", "0") == "1" and self.layer_id == 0:
+            import logging
+            _logger = logging.getLogger(__name__)
+            position = 91 if hidden_states.shape[0] > 91 else 0
+            _logger.info(f"[layer.py][SGLang Expert Input][Layer {self.layer_id}] hidden_states.shape: {hidden_states.shape}, dtype: {hidden_states.dtype}")
+            _logger.info(f"[layer.py][SGLang Expert Input][Layer {self.layer_id}] hidden_states[{position}, :5]: {hidden_states[position, :5].tolist()}")
+            _logger.info(f"[layer.py][SGLang Expert Input][Layer {self.layer_id}] w13_weight.shape: {self.w13_weight.shape}, w2_weight.shape: {self.w2_weight.shape}")
+            _logger.info(f"[layer.py][SGLang Expert Input][Layer {self.layer_id}] topk_ids.shape: {topk_output.topk_ids.shape}, topk_ids[{position}]: {topk_output.topk_ids[position].tolist()}")
+            _logger.info(f"[layer.py][SGLang Expert Input][Layer {self.layer_id}] topk_weights.shape: {topk_output.topk_weights.shape}, topk_weights[{position}]: {topk_output.topk_weights[position].tolist()}")
+
         dispatch_output = self.dispatcher.dispatch(
             hidden_states=hidden_states, topk_output=topk_output
         )
@@ -953,6 +965,16 @@ class FusedMoE(torch.nn.Module):
         if self.reduce_results and (self.moe_tp_size > 1 or self.moe_ep_size > 1):
             final_hidden_states = tensor_model_parallel_all_reduce(final_hidden_states)
 
+        # Debug: compare expert output (SGLang side) - only print for layer 0
+        import os
+        if os.environ.get("DEBUG_SGLANG_EP_MAPPING", "0") == "1" and self.layer_id == 0:
+            import logging
+            _logger = logging.getLogger(__name__)
+            _logger.info(f"[layer.py][SGLang Expert Output][Layer {self.layer_id}] output.shape: {final_hidden_states.shape}, dtype: {final_hidden_states.dtype}")
+            _logger.info(f"[layer.py][SGLang Expert Output][Layer {self.layer_id}] output[0, :5]: {final_hidden_states[0, :5].tolist()}")
+            _logger.info(f"[layer.py][SGLang Expert Output][Layer {self.layer_id}] output.norm(): {final_hidden_states.norm().item():.6f}")
+            _logger.info(f"[layer.py][SGLang Expert Output][Layer {self.layer_id}] output.sum(): {final_hidden_states.sum().item():.6f}")
+
         return final_hidden_states
 
     def run_moe_core(self, dispatch_output: DispatchOutput) -> CombineInput:
@@ -1081,7 +1103,7 @@ class FlashInferFusedMoE(FusedMoE):
             assert TopKOutputChecker.format_is_standard(
                 topk_output
             ), "Only standard topk output is supported for piecewise cuda graph"
-            return moe_forward_piecewise_cuda_graph_impl(
+            return torch.ops.sglang.moe_forward_piecewise_cuda_graph_impl(
                 hidden_states,
                 topk_output.topk_weights,
                 topk_output.topk_ids,
@@ -1210,14 +1232,16 @@ class FlashInferFP4MoE(FusedMoE):
         ), "Only bypassed topk output is supported for flashinfer fp4 moe"
 
         if is_in_piecewise_cuda_graph():
-            return flashinfer_fp4_moe_forward_piecewise_cuda_graph_impl(
-                hidden_states,
-                topk_output.router_logits,
-                topk_output.topk_config.top_k,
-                topk_output.topk_config.topk_group,
-                topk_output.topk_config.num_expert_group,
-                topk_output.topk_config.correction_bias,
-                self.layer_id,
+            return (
+                torch.ops.sglang.flashinfer_fp4_moe_forward_piecewise_cuda_graph_impl(
+                    hidden_states,
+                    topk_output.router_logits,
+                    topk_output.topk_config.top_k,
+                    topk_output.topk_config.topk_group,
+                    topk_output.topk_config.num_expert_group,
+                    topk_output.topk_config.correction_bias,
+                    self.layer_id,
+                )
             )
         else:
             return self.forward_impl(hidden_states, topk_output)
@@ -1315,7 +1339,6 @@ class FlashInferFP4MoE(FusedMoE):
         return result
 
 
-@register_custom_op(out_shape="hidden_states")
 def moe_forward_piecewise_cuda_graph_impl(
     hidden_states: torch.Tensor,
     topk_weights: torch.Tensor,
@@ -1332,7 +1355,16 @@ def moe_forward_piecewise_cuda_graph_impl(
     return moe_layer.forward_impl(hidden_states, topk_output)
 
 
-@register_custom_op(out_shape="hidden_states")
+def moe_forward_piecewise_cuda_graph_impl_fake(
+    hidden_states: torch.Tensor,
+    topk_weights: torch.Tensor,
+    topk_ids: torch.Tensor,
+    router_logits: torch.Tensor,
+    layer_id: int,
+) -> torch.Tensor:
+    return torch.empty_like(hidden_states)
+
+
 def flashinfer_fp4_moe_forward_piecewise_cuda_graph_impl(
     hidden_states: torch.Tensor,
     router_logits: torch.Tensor,
@@ -1355,3 +1387,30 @@ def flashinfer_fp4_moe_forward_piecewise_cuda_graph_impl(
     forward_context = get_forward_context()
     moe_layer = forward_context.moe_layers[layer_id]
     return moe_layer.forward_impl(hidden_states, topk_output)
+
+
+def flashinfer_fp4_moe_forward_piecewise_cuda_graph_impl_fake(
+    hidden_states: torch.Tensor,
+    router_logits: torch.Tensor,
+    top_k: int,
+    topk_group: Optional[int],
+    num_expert_group: Optional[int],
+    correction_bias: Optional[torch.Tensor],
+    layer_id: int,
+) -> torch.Tensor:
+    return torch.empty_like(hidden_states)
+
+
+direct_register_custom_op(
+    op_name="moe_forward_piecewise_cuda_graph_impl",
+    op_func=moe_forward_piecewise_cuda_graph_impl,
+    mutates_args=[],
+    fake_impl=moe_forward_piecewise_cuda_graph_impl_fake,
+)
+
+direct_register_custom_op(
+    op_name="flashinfer_fp4_moe_forward_piecewise_cuda_graph_impl",
+    op_func=flashinfer_fp4_moe_forward_piecewise_cuda_graph_impl,
+    mutates_args=[],
+    fake_impl=flashinfer_fp4_moe_forward_piecewise_cuda_graph_impl_fake,
+)
diff --git a/python/sglang/srt/layers/moe/token_dispatcher/standard.py b/python/sglang/srt/layers/moe/token_dispatcher/standard.py
index 2c959c7..e843ac4 100644
--- a/python/sglang/srt/layers/moe/token_dispatcher/standard.py
+++ b/python/sglang/srt/layers/moe/token_dispatcher/standard.py
@@ -32,6 +32,9 @@ from sglang.srt.layers.moe.utils import (
 )
 from sglang.srt.utils.common import get_bool_env_var, is_hip, is_sm120_supported
 
+import logging
+logger = logging.getLogger(__name__)
+
 _is_hip = is_hip()
 _use_aiter = get_bool_env_var("SGLANG_USE_AITER") and _is_hip
 
@@ -93,11 +96,12 @@ class StandardDispatcher(BaseDispatcher):
         )
         self.moe_ep_rank = get_moe_expert_parallel_rank()
         self.local_expert_mapping = None
+        self.layer_id = moe_runner_config.layer_id  # Store layer_id from config
 
     def dispatch(
         self, hidden_states: torch.Tensor, topk_output: TopKOutput
     ) -> StandardDispatchOutput:
-
+        import os
         if should_use_flashinfer_cutlass_moe_fp4_allgather():
             # all-gather fp4 hidden states
             from flashinfer import nvfp4_block_scale_interleave
@@ -167,10 +171,50 @@ class StandardDispatcher(BaseDispatcher):
                     )
 
         if self.local_expert_mapping is not None and not _use_aiter:
+            # Debug print for EP token mapping (only print for layer 0)
+            should_print = (
+                os.environ.get("DEBUG_SGLANG_EP_MAPPING", "0") == "1"
+                and self.layer_id == 0
+            )
+            
+            if should_print:
+                topk_ids_before = topk_output.topk_ids
+                num_tokens = topk_ids_before.shape[0]
+                topk = topk_ids_before.shape[1]
+                rank = self.moe_ep_rank
+                local_start = rank * self.num_local_routed_experts
+                local_end = local_start + self.num_local_routed_experts
+                
+                logger.info(f"[standard.py][SGLang EP Mapping][Rank {rank}][Layer {self.layer_id}] EP config: ep_size={self.moe_ep_size}, ep_rank={rank}")
+                logger.info(f"[standard.py][SGLang EP Mapping][Rank {rank}][Layer {self.layer_id}] num_experts={self.num_experts}, num_local_experts={self.num_local_routed_experts}")
+                logger.info(f"[standard.py][SGLang EP Mapping][Rank {rank}][Layer {self.layer_id}] num_tokens={num_tokens}, topk={topk}")
+                logger.info(f"[standard.py][SGLang EP Mapping][Rank {rank}][Layer {self.layer_id}] Local expert range: [{local_start}, {local_end})")
+                logger.info(f"[standard.py][SGLang EP Mapping][Rank {rank}][Layer {self.layer_id}] local_expert_mapping: {self.local_expert_mapping.tolist()}")
+                
+                # Count tokens per expert (global ids)
+                logger.info(f"[standard.py][SGLang EP Mapping][Rank {rank}][Layer {self.layer_id}] Token distribution (global expert ids):")
+                for expert_id in range(self.num_experts):
+                    count = (topk_ids_before == expert_id).sum().item()
+                    is_local = self.local_expert_mapping[expert_id].item() >= 0
+                    #logger.info(f"[standard.py]  Expert {expert_id}: {count} tokens, local={is_local}")
+                    
             if TopKOutputChecker.format_is_standard(topk_output):
+                # Save global topk_ids before mapping
+                global_topk_ids = topk_output.topk_ids.clone()
                 topk_output = topk_output._replace(
                     topk_ids=self.local_expert_mapping[topk_output.topk_ids]
                 )
+                # Debug print after mapping - use SLIME_DEBUG_ATTN
+                import os
+                should_print_attn = os.environ.get("SLIME_DEBUG_ATTN", "0") == "1" and self.layer_id == 0
+                if should_print or should_print_attn:
+                    pos = 0
+                    logger.info(f"[standard.py][SGLang EP Mapping][Rank {rank}][Layer {self.layer_id}] Global topk_ids[{pos},:]: {global_topk_ids[pos, :].tolist()}")
+                    logger.info(f"[standard.py][SGLang EP Mapping][Rank {rank}][Layer {self.layer_id}] Local topk_ids[{pos},:]: {topk_output.topk_ids[pos, :].tolist()}")
+                    logger.info(f"[standard.py][SGLang EP Mapping][Rank {rank}][Layer {self.layer_id}] topk_weights[{pos},:]: {topk_output.topk_weights[pos, :].tolist()}")
+                    logger.info(f"[standard.py][SGLang EP Mapping][Rank {rank}][Layer {self.layer_id}] hidden_states[{pos},:5]: {hidden_states[pos, :5].tolist()}")
+                    logger.info(f"[standard.py][SGLang EP Mapping][Rank {rank}][Layer {self.layer_id}] hidden_states sum: {hidden_states[pos].float().sum().item():.6f}")
+                
             elif TopKOutputChecker.format_is_triton_kernels(topk_output):
                 raise NotImplementedError()
 
diff --git a/python/sglang/srt/models/qwen3.py b/python/sglang/srt/models/qwen3.py
index 47a1a4e..38102e2 100644
--- a/python/sglang/srt/models/qwen3.py
+++ b/python/sglang/srt/models/qwen3.py
@@ -139,8 +139,29 @@ class Qwen3Attention(nn.Module):
         self.alt_stream = alt_stream
 
     def forward_prepare_native(self, positions, hidden_states):
+        import os
+        layer_id = self.attn.layer_id
+        debug_attn = os.environ.get("SLIME_DEBUG_ATTN", "0") == "1" and layer_id <= 1
+        
         qkv, _ = self.qkv_proj(hidden_states)
         q, k, v = qkv.split([self.q_size, self.kv_size, self.kv_size], dim=-1)
+        
+        # DEBUG: QKV after projection (before qk_norm and RoPE)
+        if debug_attn:
+            tp_size = get_tensor_model_parallel_world_size()
+            tp_rank = get_tensor_model_parallel_rank()
+            attn_tp_size = get_attention_tp_size()
+            attn_tp_rank = get_attention_tp_rank()
+            pos = 0
+            prefix = f"[qwen3.py][SGLang][TP {tp_rank}/{tp_size}][AttnTP {attn_tp_rank}/{attn_tp_size}][Layer {layer_id}]"
+            logger.info(f"{prefix} QKV output (before qk_norm, before RoPE) q.shape: {q.shape}")
+            q_val = q[pos, :5] if q.dim() == 2 else q[pos, :5]
+            k_val = k[pos, :5] if k.dim() == 2 else k[pos, :5]
+            v_val = v[pos, :5] if v.dim() == 2 else v[pos, :5]
+            logger.info(f"{prefix} q (before qk_norm)[{pos},:5]: {q_val.tolist()}")
+            logger.info(f"{prefix} k (before qk_norm)[{pos},:5]: {k_val.tolist()}")
+            logger.info(f"{prefix} v[{pos},:5]: {v_val.tolist()}")
+        
         q, k = apply_qk_norm(
             q=q,
             k=k,
@@ -149,6 +170,12 @@ class Qwen3Attention(nn.Module):
             head_dim=self.head_dim,
             alt_stream=self.alt_stream,
         )
+        
+        # DEBUG: After qk_norm (before RoPE)
+        if debug_attn:
+            logger.info(f"{prefix} After qk_norm (before RoPE) q[{pos},:5]: {q[pos, :5].tolist()}")
+            logger.info(f"{prefix} After qk_norm (before RoPE) k[{pos},:5]: {k[pos, :5].tolist()}")
+        
         q, k = self.rotary_emb(positions, q, k)
         return q, k, v
 
@@ -178,6 +205,22 @@ class Qwen3Attention(nn.Module):
         hidden_states: torch.Tensor,
         forward_batch: ForwardBatch,
     ) -> torch.Tensor:
+        import os
+        layer_id = self.attn.layer_id
+        debug_attn = os.environ.get("SLIME_DEBUG_ATTN", "0") == "1" and layer_id <= 1
+        
+        if debug_attn:
+            tp_size = get_tensor_model_parallel_world_size()
+            tp_rank = get_tensor_model_parallel_rank()
+            attn_tp_size = get_attention_tp_size()
+            attn_tp_rank = get_attention_tp_rank()
+            pos = 0
+            prefix = f"[qwen3.py][SGLang][TP {tp_rank}/{tp_size}][AttnTP {attn_tp_rank}/{attn_tp_size}][Layer {layer_id}]"
+            # Attention input
+            logger.info(f"{prefix} Attention INPUT hidden_states.shape: {hidden_states.shape}")
+            logger.info(f"{prefix} Attention INPUT hidden_states[{pos},:5]: {hidden_states[pos, :5].tolist()}")
+            logger.info(f"{prefix} Attention INPUT hidden_states sum: {hidden_states[pos].float().sum().item():.6f}")
+        
         if get_global_server_args().rl_on_policy_target is not None:
             hidden_states = hidden_states.bfloat16()
 
@@ -193,12 +236,41 @@ class Qwen3Attention(nn.Module):
                 forward_batch=forward_batch,
             )
 
+        # DEBUG: QKV after projection and RoPE
+        if debug_attn:
+            logger.info(f"{prefix} QKV output (after RoPE) q.shape: {q.shape}")
+            q_val = q[pos, :5] if q.dim() == 2 else (q[pos, 0, :5] if q.dim() == 3 else q[pos, :5])
+            k_val = k[pos, :5] if k.dim() == 2 else (k[pos, 0, :5] if k.dim() == 3 else k[pos, :5])
+            v_val = v[pos, :5] if v.dim() == 2 else (v[pos, 0, :5] if v.dim() == 3 else v[pos, :5])
+            logger.info(f"{prefix} q[{pos},:5]: {q_val.tolist()}")
+            logger.info(f"{prefix} k[{pos},:5]: {k_val.tolist()}")
+            logger.info(f"{prefix} v[{pos},:5]: {v_val.tolist()}")
+            logger.info(f"{prefix} After RoPE q norm: {q[pos].float().norm().item():.6f}")
+            logger.info(f"{prefix} After RoPE k norm: {k[pos].float().norm().item():.6f}")
+
         if get_global_server_args().rl_on_policy_target is not None:
             q = q.to(torch.bfloat16)
             k = k.to(torch.bfloat16)
 
         attn_output = self.attn(q, k, v, forward_batch)
+        
+        # DEBUG: Core attention output (before o_proj)
+        if debug_attn:
+            logger.info(f"{prefix} Core attention output shape: {attn_output.shape}")
+            attn_out_val = attn_output[pos, :5] if attn_output.dim() == 2 else attn_output[pos, :5]
+            logger.info(f"{prefix} Core attention output[{pos},:5]: {attn_out_val.tolist()}")
+            logger.info(f"{prefix} Core attention output norm: {attn_output[pos].float().norm().item():.6f}")
+            logger.info(f"{prefix} Core attention output sum: {attn_output[pos].float().sum().item():.6f}")
+        
         output, _ = self.o_proj(attn_output)
+        
+        # DEBUG: O_proj output (BEFORE all-reduce, since reduce_results=False)
+        if debug_attn:
+            logger.info(f"{prefix} o_proj output shape: {output.shape}")
+            output_val = output[pos, :5] if output.dim() == 2 else output[pos, :5]
+            logger.info(f"{prefix} o_proj output (BEFORE all-reduce)[{pos},:5]: {output_val.tolist()}")
+            logger.info(f"{prefix} o_proj output sum (BEFORE all-reduce): {output[pos].float().sum().item():.6f}")
+        
         return output
 
 
@@ -290,6 +362,39 @@ class Qwen3DecoderLayer(nn.Module):
                 forward_batch=forward_batch,
             )
 
+        # DEBUG: Before prepare_mlp (attention output, BEFORE all-reduce)
+        import os
+        layer_id = self.self_attn.attn.layer_id  # Get layer_id from attention module
+        if os.environ.get("SLIME_DEBUG_ATTN", "0") == "1" and layer_id <= 1:
+            from sglang.srt.layers.dp_attention import get_attention_tp_size, get_attention_tp_rank
+            from sglang.srt.tp_invariant_ops import tree_all_reduce_sum
+            from sglang.srt.distributed import get_tp_group
+            attn_tp_size = get_attention_tp_size()
+            attn_tp_rank = get_attention_tp_rank()
+            tp_size = get_tensor_model_parallel_world_size()
+            tp_rank = get_tensor_model_parallel_rank()
+            pos = 0
+            prefix = f"[qwen3.py][SGLang][TP {tp_rank}/{tp_size}][AttnTP {attn_tp_rank}/{attn_tp_size}][Layer {layer_id}]"
+            logger.info(f"{prefix} Before prepare_mlp (BEFORE all-reduce), hidden_states[{pos},:5]: {hidden_states[pos, :5].tolist()}")
+            logger.info(f"{prefix} Before prepare_mlp (BEFORE all-reduce), hidden_states sum: {hidden_states[pos].float().sum().item():.6f}")
+            
+            # Manually do all-reduce for debug comparison with Megatron
+            # Use tree_all_reduce_sum to match what prepare_mlp actually uses in fsdp mode
+            if attn_tp_size > 1:
+                # Method 1: tree_all_reduce_sum (what SGLang actually uses in fsdp mode)
+                debug_tree_allreduce = tree_all_reduce_sum(hidden_states.clone(), device_group=get_tp_group().device_group)
+                logger.info(f"{prefix} DEBUG: After tree_all_reduce_sum (AFTER all-reduce), hidden_states[{pos},:5]: {debug_tree_allreduce[pos, :5].tolist()}")
+                logger.info(f"{prefix} DEBUG: After tree_all_reduce_sum (AFTER all-reduce), hidden_states sum: {debug_tree_allreduce[pos].float().sum().item():.6f}")
+                
+                # Method 2: NCCL all_reduce (what Megatron uses)
+                import torch.distributed as dist
+                debug_nccl_allreduce = hidden_states.clone()
+                dist.all_reduce(debug_nccl_allreduce, group=get_tp_group().device_group)
+                logger.info(f"{prefix} DEBUG: After NCCL all_reduce (Megatron style), hidden_states[{pos},:5]: {debug_nccl_allreduce[pos, :5].tolist()}")
+                logger.info(f"{prefix} DEBUG: After NCCL all_reduce (Megatron style), hidden_states sum: {debug_nccl_allreduce[pos].float().sum().item():.6f}")
+            else:
+                logger.info(f"{prefix} DEBUG: attn_tp_size=1, no all-reduce needed")
+
         # Fully Connected
         hidden_states, residual = self.layer_communicator.prepare_mlp(
             hidden_states,
@@ -301,12 +406,33 @@ class Qwen3DecoderLayer(nn.Module):
                 else None
             ),
         )
+        
+        # DEBUG: After prepare_mlp (after all-reduce + LayerNorm) - this is MLP input
+        if os.environ.get("SLIME_DEBUG_ATTN", "0") == "1" and layer_id <= 1:
+            logger.info(f"{prefix} After prepare_mlp (all-reduce + LN) = MLP INPUT, hidden_states[{pos},:5]: {hidden_states[pos, :5].tolist()}")
+            logger.info(f"{prefix} After prepare_mlp = MLP INPUT, hidden_states sum: {hidden_states[pos].float().sum().item():.6f}")
+            if residual is not None:
+                logger.info(f"{prefix} After prepare_mlp, residual[{pos},:5]: {residual[pos, :5].tolist()}")
+                logger.info(f"{prefix} After prepare_mlp, residual sum: {residual[pos].float().sum().item():.6f}")
+
         hidden_states = self.mlp(hidden_states)
+        
+        # DEBUG: After MLP (before postprocess_layer) - MLP output includes all-reduce from down_proj
+        if os.environ.get("SLIME_DEBUG_ATTN", "0") == "1" and layer_id <= 1:
+            logger.info(f"{prefix} After MLP (before postprocess) = MLP OUTPUT, hidden_states[{pos},:5]: {hidden_states[pos, :5].tolist()}")
+            logger.info(f"{prefix} After MLP = MLP OUTPUT, hidden_states sum: {hidden_states[pos].float().sum().item():.6f}")
+        
         if _is_npu and get_cmo_stream():
             wait_cmo_stream()
         hidden_states, residual = self.layer_communicator.postprocess_layer(
             hidden_states, residual, forward_batch
         )
+        
+        # DEBUG: After postprocess_layer - final layer output
+        if os.environ.get("SLIME_DEBUG_ATTN", "0") == "1" and layer_id <= 1:
+            logger.info(f"{prefix} After postprocess_layer = LAYER OUTPUT, hidden_states[{pos},:5]: {hidden_states[pos, :5].tolist()}")
+            logger.info(f"{prefix} After postprocess_layer = LAYER OUTPUT, hidden_states sum: {hidden_states[pos].float().sum().item():.6f}")
+        
         return hidden_states, residual
 
 
diff --git a/python/sglang/srt/models/qwen3_moe.py b/python/sglang/srt/models/qwen3_moe.py
index e277d46..8054501 100644
--- a/python/sglang/srt/models/qwen3_moe.py
+++ b/python/sglang/srt/models/qwen3_moe.py
@@ -32,6 +32,7 @@ from sglang.srt.distributed import (
     get_tensor_model_parallel_rank,
     get_tensor_model_parallel_world_size,
     tensor_model_parallel_all_reduce,
+    tensor_model_parallel_tree_all_reduce,
 )
 from sglang.srt.eplb.expert_distribution import get_global_expert_distribution_recorder
 from sglang.srt.eplb.expert_location import ModelConfigForExpertLocation
@@ -75,7 +76,7 @@ from sglang.srt.utils import (
     is_non_idle_and_non_empty,
     is_npu,
 )
-
+import os
 _is_cuda = is_cuda()
 
 if _is_cuda:
@@ -94,6 +95,7 @@ _is_npu = is_npu()
 if _is_npu:
     from sgl_kernel_npu.norm.split_qkv_rmsnorm_rope import split_qkv_rmsnorm_rope
 
+logger.info("AAAAA Qwen3_moe.py")
 
 def compute_yarn_parameters(
     config: PretrainedConfig,
@@ -216,6 +218,7 @@ class Qwen3MoeSparseMoeBlock(nn.Module):
         prefix: str = "",
     ):
         super().__init__()
+        self.use_fp32_route = get_global_server_args().enable_fp32_route
         self.tp_size = get_tensor_model_parallel_world_size()
         self.layer_id = layer_id
         if self.tp_size > config.num_experts:
@@ -244,13 +247,23 @@ class Qwen3MoeSparseMoeBlock(nn.Module):
             routing_method_type=RoutingMethodType.Renormalize,
         )
 
-        self.gate = ReplicatedLinear(
-            config.hidden_size,
-            config.num_experts,
-            bias=False,
-            quant_config=None,
-            prefix=add_prefix("gate", prefix),
-        )
+        if self.use_fp32_route:
+            self.gate = ReplicatedLinear(
+                config.hidden_size,
+                config.num_experts,
+                bias=False,
+                quant_config=None,
+                prefix=add_prefix("gate", prefix),
+                params_dtype=torch.float32,
+            )
+        else:
+            self.gate = ReplicatedLinear(
+                config.hidden_size,
+                config.num_experts,
+                bias=False,
+                quant_config=None,
+                prefix=add_prefix("gate", prefix),
+            )
 
         if get_moe_a2a_backend().is_deepep():
             # TODO: we will support tp < ep in the future
@@ -294,9 +307,26 @@ class Qwen3MoeSparseMoeBlock(nn.Module):
         num_tokens, hidden_dim = hidden_states.shape
         hidden_states = hidden_states.view(-1, hidden_dim)
 
-        # router_logits: (num_tokens, n_experts)
-        router_logits, _ = self.gate(hidden_states)
+        # DEBUG: MoE input
+        debug_moe = os.environ.get("SLIME_DEBUG_ATTN", "0") == "1" and self.layer_id == 0
+        if debug_moe:
+            tp_rank = get_tensor_model_parallel_rank()
+            tp_size = get_tensor_model_parallel_world_size()
+            pos = 0
+            prefix = f"[qwen3_moe.py][SGLang MoE][TP {tp_rank}/{tp_size}][Layer {self.layer_id}]"
+            logger.info(f"{prefix} MoE INPUT hidden_states[{pos},:5]: {hidden_states[pos, :5].tolist()}")
+            logger.info(f"{prefix} MoE INPUT hidden_states sum: {hidden_states[pos].float().sum().item():.6f}")
 
+        # router_logits: (num_tokens, n_experts)
+        if self.use_fp32_route:
+            if debug_moe:
+                logger.info(f"{prefix} Using fp32 route")
+            router_logits, _ = self.gate(hidden_states.to(torch.float32))
+        else:
+            router_logits, _ = self.gate(hidden_states)
+            if debug_moe:
+                logger.info(f"{prefix} Using fp16/bf16 route")
+                
         if get_global_server_args().rl_on_policy_target is not None:
             routing_weights = F.softmax(router_logits, dim=1, dtype=torch.float)
             routing_weights, selected_experts = torch.topk(
@@ -309,17 +339,58 @@ class Qwen3MoeSparseMoeBlock(nn.Module):
                 topk_ids=selected_experts,
                 router_logits=router_logits,
             )
+            # DEBUG: Router details
+            if debug_moe:
+                logger.info(f"{prefix} Router logits[{pos},:8]: {router_logits[pos, :8].tolist()}")
+                logger.info(f"{prefix} Router logits sum: {router_logits[pos].float().sum().item():.6f}")
+                logger.info(f"{prefix} Routing weights (after softmax+topk+renorm)[{pos},:]: {routing_weights[pos, :].tolist()}")
+                logger.info(f"{prefix} Selected experts[{pos},:]: {selected_experts[pos, :].tolist()}")
         else:
             topk_output = self.topk(hidden_states, router_logits)
 
+        # DEBUG: Expert INPUT before calling experts
+        if debug_moe:
+            # Log hidden_states going into expert computation
+            logger.info(f"{prefix} Expert INPUT hidden_states[{pos},:5]: {hidden_states[pos, :5].tolist()}")
+            logger.info(f"{prefix} Expert INPUT hidden_states sum: {hidden_states[pos].float().sum().item():.6f}")
+            logger.info(f"{prefix} Expert INPUT topk_weights[{pos},:]: {topk_output.topk_weights[pos, :].tolist()}")
+            logger.info(f"{prefix} Expert INPUT topk_ids[{pos},:]: {topk_output.topk_ids[pos, :].tolist()}")
+            
+            # Log expert weights shape and sample values
+            if hasattr(self.experts, 'w13_weight'):
+                w13 = self.experts.w13_weight
+                w2 = self.experts.w2_weight
+                logger.info(f"{prefix} w13_weight.shape: {w13.shape}, w2_weight.shape: {w2.shape}")
+                logger.info(f"{prefix} w13_weight[0,0,:5]: {w13[0, 0, :5].tolist()}")
+                logger.info(f"{prefix} w13_weight sum: {w13.float().sum().item():.6f}")
+                logger.info(f"{prefix} w2_weight[0,0,:5]: {w2[0, 0, :5].tolist()}")
+                logger.info(f"{prefix} w2_weight sum: {w2.float().sum().item():.6f}")
+
         final_hidden_states = self.experts(hidden_states, topk_output)
+        
+        # DEBUG: MoE output before all-reduce
+        if debug_moe:
+            logger.info(f"{prefix} MoE experts OUTPUT (BEFORE all-reduce)[{pos},:5]: {final_hidden_states[pos, :5].tolist()}")
+            logger.info(f"{prefix} MoE experts OUTPUT sum (BEFORE all-reduce): {final_hidden_states[pos].float().sum().item():.6f}")
+        
         if (
             self.tp_size > 1
             and not should_allreduce_fusion
             and not use_reduce_scatter
             and not should_use_flashinfer_cutlass_moe_fp4_allgather()
         ):
-            final_hidden_states = tensor_model_parallel_all_reduce(final_hidden_states)
+            if get_global_server_args().rl_on_policy_target == "fsdp_tp" or get_global_server_args().rl_on_policy_target == "fsdp":
+                final_hidden_states = tensor_model_parallel_tree_all_reduce(final_hidden_states)
+            else:
+                final_hidden_states = tensor_model_parallel_all_reduce(final_hidden_states)
+            
+            # DEBUG: MoE output after all-reduce
+            if debug_moe:
+                logger.info(f"{prefix} MoE OUTPUT (AFTER all-reduce)[{pos},:5]: {final_hidden_states[pos, :5].tolist()}")
+                logger.info(f"{prefix} MoE OUTPUT sum (AFTER all-reduce): {final_hidden_states[pos].float().sum().item():.6f}")
+        else:
+            if debug_moe:
+                logger.info(f"{prefix} MoE OUTPUT (no all-reduce, tp_size={self.tp_size}, fusion={should_allreduce_fusion})")
 
         return final_hidden_states.view(num_tokens, hidden_dim)
 
@@ -568,9 +639,38 @@ class Qwen3MoeAttention(nn.Module):
         hidden_states: torch.Tensor,
         forward_batch: ForwardBatch,
     ):
+        # DEBUG: Attention input (after input_layernorm in decoder layer)
+        import os
+        if os.environ.get("SLIME_DEBUG_ATTN", "0") == "1" and self.attn.layer_id == 0:
+            tp_rank = get_tensor_model_parallel_rank()
+            pos = 0
+            prefix = f"[qwen3_moe.py][SGLang][TP {tp_rank}][Layer {self.attn.layer_id}]"
+            logger.info(f"{prefix} Attention input[{pos},:5]: {hidden_states[pos, :5].tolist()}")
+            logger.info(f"{prefix} Attention input norm: {hidden_states[pos].float().norm().item():.6f}")
+        
         qkv, _ = self.qkv_proj(hidden_states)
+        
+        # DEBUG: QKV output (before RoPE)
+        if os.environ.get("SLIME_DEBUG_ATTN", "0") == "1" and self.attn.layer_id == 0:
+            q_raw, k_raw, v_raw = qkv.split([self.q_size, self.kv_size, self.kv_size], dim=-1)
+            q_reshaped = q_raw.view(-1, self.num_heads, self.head_dim)
+            k_reshaped = k_raw.view(-1, self.num_kv_heads, self.head_dim)
+            v_reshaped = v_raw.view(-1, self.num_kv_heads, self.head_dim)
+            logger.info(f"{prefix} QKV output (before RoPE) query.shape: {q_reshaped.shape}")
+            logger.info(f"{prefix} query[{pos},0,:5]: {q_reshaped[pos, 0, :5].tolist()}")
+            logger.info(f"{prefix} key[{pos},0,:5]: {k_reshaped[pos, 0, :5].tolist()}")
+            logger.info(f"{prefix} value[{pos},0,:5]: {v_reshaped[pos, 0, :5].tolist()}")
 
         q, k, v = self.apply_qk_norm_rope(qkv, positions, forward_batch)
+        
+        # DEBUG: Q, K after RoPE
+        if os.environ.get("SLIME_DEBUG_ATTN", "0") == "1" and self.attn.layer_id == 0:
+            q_reshaped = q.view(-1, self.num_heads, self.head_dim)
+            k_reshaped = k.view(-1, self.num_kv_heads, self.head_dim)
+            logger.info(f"{prefix} After RoPE query[{pos},0,:5]: {q_reshaped[pos, 0, :5].tolist()}")
+            logger.info(f"{prefix} After RoPE key[{pos},0,:5]: {k_reshaped[pos, 0, :5].tolist()}")
+            logger.info(f"{prefix} After RoPE query norm: {q[pos].float().norm().item():.6f}")
+            logger.info(f"{prefix} After RoPE key norm: {k[pos].float().norm().item():.6f}")
 
         inner_state = q, k, v, forward_batch
         return None, forward_batch, inner_state
@@ -671,7 +771,38 @@ class Qwen3MoeAttention(nn.Module):
             fb,
             save_kv_cache=save_kv_cache,
         )
+        
+        # DEBUG: Core attention output (before output projection)
+        import os
+        if os.environ.get("SLIME_DEBUG_ATTN", "0") == "1" and self.attn.layer_id == 0:
+            tp_rank = get_tensor_model_parallel_rank()
+            tp_size = get_tensor_model_parallel_world_size()
+            from sglang.srt.layers.dp_attention import get_attention_tp_rank, get_attention_tp_size
+            attn_tp_rank = get_attention_tp_rank()
+            attn_tp_size = get_attention_tp_size()
+            pos = 0  # Match Megatron's debug position
+            prefix = f"[qwen3_moe.py][SGLang][TP {tp_rank}/{tp_size}][AttnTP {attn_tp_rank}/{attn_tp_size}][Layer {self.attn.layer_id}]"
+            logger.info(f"{prefix} Core attention output shape: {attn_output.shape}")
+            logger.info(f"{prefix} Core attention output[{pos},:5]: {attn_output[pos, :5].tolist()}")
+            logger.info(f"{prefix} Core attention output norm: {attn_output[pos].float().norm().item():.6f}")
+            
+            # Debug o_proj weight with sum
+            weight = self.o_proj.weight
+            logger.info(f"{prefix} o_proj weight shape: {weight.shape}")
+            logger.info(f"{prefix} o_proj weight[0,:5]: {weight[0, :5].tolist()}")
+            logger.info(f"{prefix} o_proj weight sum: {weight.float().sum().item():.6f}")
+            
+            # Debug o_proj input with sum
+            logger.info(f"{prefix} o_proj input[{pos},:5]: {attn_output[pos, :5].tolist()}")
+            logger.info(f"{prefix} o_proj input sum: {attn_output[pos].float().sum().item():.6f}")
+        
         output, _ = self.o_proj(attn_output)
+        
+        # DEBUG: After o_proj (attention output) - before all-reduce
+        if os.environ.get("SLIME_DEBUG_ATTN", "0") == "1" and self.attn.layer_id == 0:
+            logger.info(f"{prefix} Attention output (after o_proj, BEFORE all-reduce)[{pos},:5]: {output[pos, :5].tolist()}")
+            logger.info(f"{prefix} Attention output sum (BEFORE all-reduce): {output[pos].float().sum().item():.6f}")
+        
         return output
 
     def forward(
@@ -783,6 +914,7 @@ class Qwen3MoeDecoderLayer(nn.Module):
             post_attention_layernorm=self.post_attention_layernorm,
             allow_reduce_scatter=True,
             is_last_layer=(self.layer_id == self.config.num_hidden_layers - 1),
+            layer_id=self.layer_id,
         )
 
     def forward(
@@ -812,9 +944,92 @@ class Qwen3MoeDecoderLayer(nn.Module):
                 forward_batch=forward_batch,
             )
 
+        # DEBUG: Attention output (before post_attention_layernorm)
+        import os
+        if os.environ.get("SLIME_DEBUG_ROUTER", "0") == "1" and self.layer_id == 0:
+            rank = get_tensor_model_parallel_rank()
+            pos = 0
+            prefix = f"[qwen3_moe.py][SGLang Decoder][Rank {rank}][Layer {self.layer_id}]"
+            logger.info(f"{prefix} Attention output (before post_attn_norm)[{pos},:5]: "
+                        f"{hidden_states[pos, :5].tolist()}, dtype: {hidden_states.dtype}")
+            if residual is not None:
+                logger.info(f"{prefix} Residual[{pos},:5]: {residual[pos, :5].tolist()}")
+
+        # DEBUG: Setup debug variables for this layer
+        debug_layer = os.environ.get("SLIME_DEBUG_ATTN", "0") == "1" and self.layer_id == 0
+        if debug_layer:
+            from sglang.srt.layers.dp_attention import get_attention_tp_size, get_attention_tp_rank
+            from sglang.srt.tp_invariant_ops import tree_all_reduce_sum
+            from sglang.srt.distributed import get_tp_group
+            import torch.distributed as dist
+            attn_tp_size = get_attention_tp_size()
+            attn_tp_rank = get_attention_tp_rank()
+            tp_size = get_tensor_model_parallel_world_size()
+            tp_rank = get_tensor_model_parallel_rank()
+            pos = 0
+            prefix = f"[qwen3_moe.py][SGLang][TP {tp_rank}/{tp_size}][AttnTP {attn_tp_rank}/{attn_tp_size}][Layer {self.layer_id}]"
+            
+            # DEBUG: Print LayerScatterModes to compare with Dense
+            logger.info(f"{prefix} LayerScatterModes: mlp_mode={self.layer_scatter_modes.mlp_mode}, "
+                        f"middle_residual_mode={self.layer_scatter_modes.middle_residual_mode}, "
+                        f"is_layer_sparse={self.is_layer_sparse}")
+            
+            logger.info(f"{prefix} Before prepare_mlp (BEFORE all-reduce), hidden_states[{pos},:5]: {hidden_states[pos, :5].tolist()}")
+            logger.info(f"{prefix} Before prepare_mlp (BEFORE all-reduce), hidden_states sum: {hidden_states[pos].float().sum().item():.6f}")
+            
+            # Manually do all-reduce for debug comparison with Megatron
+            # Compare tree_all_reduce_sum (what SGLang uses) vs NCCL all_reduce (what Megatron uses)
+            if attn_tp_size > 1:
+                # Method 1: tree_all_reduce_sum (what SGLang actually uses in fsdp mode)
+                debug_tree_allreduce = tree_all_reduce_sum(hidden_states.clone(), device_group=get_tp_group().device_group)
+                logger.info(f"{prefix} DEBUG: After tree_all_reduce_sum (AFTER all-reduce), hidden_states[{pos},:5]: {debug_tree_allreduce[pos, :5].tolist()}")
+                logger.info(f"{prefix} DEBUG: After tree_all_reduce_sum (AFTER all-reduce), hidden_states sum: {debug_tree_allreduce[pos].float().sum().item():.6f}")
+                
+                # Method 2: NCCL all_reduce (what Megatron uses by default)
+                debug_nccl_allreduce = hidden_states.clone()
+                dist.all_reduce(debug_nccl_allreduce, group=get_tp_group().device_group)
+                logger.info(f"{prefix} DEBUG: After NCCL all_reduce (Megatron style), hidden_states[{pos},:5]: {debug_nccl_allreduce[pos, :5].tolist()}")
+                logger.info(f"{prefix} DEBUG: After NCCL all_reduce (Megatron style), hidden_states sum: {debug_nccl_allreduce[pos].float().sum().item():.6f}")
+            else:
+                logger.info(f"{prefix} DEBUG: attn_tp_size=1, no all-reduce needed")
+        
+        # DEBUG: Before prepare_mlp - manually compute all-reduce + residual add to trace difference
+        if debug_layer:
+            logger.info(f"{prefix} hidden_states (attn out, before all-reduce)[{pos},:5]: {hidden_states[pos, :5].tolist()}")
+            logger.info(f"{prefix} residual (original input)[{pos},:5]: {residual[pos, :5].tolist()}")
+            
+            # Step 1: All-reduce
+            debug_allreduced = tree_all_reduce_sum(hidden_states.clone(), device_group=get_tp_group().device_group)
+            logger.info(f"{prefix} Step1: After all-reduce[{pos},:5]: {debug_allreduced[pos, :5].tolist()}")
+            
+            # Step 2: Residual add (in bf16, like SGLang with fp32_residual=False)
+            debug_after_resadd = debug_allreduced + residual
+            logger.info(f"{prefix} Step2: After resadd (bf16)[{pos},:5]: {debug_after_resadd[pos, :5].tolist()}")
+            logger.info(f"{prefix} Step2: After resadd sum: {debug_after_resadd[pos].float().sum().item():.6f}")
+            
+            # Step 3: Manual layernorm to compare with actual
+            debug_for_ln = debug_after_resadd[pos].to(torch.float32)
+            variance = debug_for_ln.pow(2).mean()
+            eps = self.post_attention_layernorm.variance_epsilon
+            debug_normalized = debug_for_ln * torch.rsqrt(variance + eps)
+            weight = self.post_attention_layernorm.weight.data
+            debug_ln_out = weight * debug_normalized.to(hidden_states.dtype)
+            logger.info(f"{prefix} Step3: Manual LN output[:5]: {debug_ln_out[:5].tolist()}")
+            logger.info(f"{prefix} LN weight[:5]: {weight[:5].tolist()}")
+            logger.info(f"{prefix} LN epsilon: {eps}")
+        
         hidden_states, residual = self.layer_communicator.prepare_mlp(
             hidden_states, residual, forward_batch
         )
+        
+        # DEBUG: After prepare_mlp (all-reduce + LayerNorm) = MoE INPUT
+        if debug_layer:
+            logger.info(f"{prefix} After prepare_mlp (all-reduce + LN) = MoE INPUT[{pos},:5]: {hidden_states[pos, :5].tolist()}")
+            logger.info(f"{prefix} After prepare_mlp = MoE INPUT sum: {hidden_states[pos].float().sum().item():.6f}")
+            if residual is not None:
+                logger.info(f"{prefix} After prepare_mlp, residual[{pos},:5]: {residual[pos, :5].tolist()}")
+                logger.info(f"{prefix} After prepare_mlp, residual sum: {residual[pos].float().sum().item():.6f}")
+
 
         should_allreduce_fusion = (
             self.layer_communicator.should_fuse_mlp_allreduce_with_next_layer(
@@ -830,6 +1045,11 @@ class Qwen3MoeDecoderLayer(nn.Module):
         hidden_states = self.mlp(
             hidden_states, forward_batch, should_allreduce_fusion, use_reduce_scatter
         )
+        
+        # DEBUG: After MoE (before postprocess_layer) = MoE BLOCK OUTPUT
+        if debug_layer:
+            logger.info(f"{prefix} After MoE (before postprocess) = MoE BLOCK OUTPUT[{pos},:5]: {hidden_states[pos, :5].tolist()}")
+            logger.info(f"{prefix} After MoE = MoE BLOCK OUTPUT sum: {hidden_states[pos].float().sum().item():.6f}")
 
         if should_allreduce_fusion:
             hidden_states._sglang_needs_allreduce_fusion = True
@@ -837,6 +1057,14 @@ class Qwen3MoeDecoderLayer(nn.Module):
             hidden_states, residual = self.layer_communicator.postprocess_layer(
                 hidden_states, residual, forward_batch
             )
+        
+        # DEBUG: After postprocess_layer - final layer output
+        if debug_layer:
+            logger.info(f"{prefix} After postprocess_layer = LAYER OUTPUT[{pos},:5]: {hidden_states[pos, :5].tolist()}")
+            logger.info(f"{prefix} After postprocess_layer = LAYER OUTPUT sum: {hidden_states[pos].float().sum().item():.6f}")
+            if residual is not None:
+                logger.info(f"{prefix} After postprocess_layer, residual[{pos},:5]: {residual[pos, :5].tolist()}")
+                logger.info(f"{prefix} After postprocess_layer, residual sum: {residual[pos].float().sum().item():.6f}")
 
         return hidden_states, residual
 
@@ -939,6 +1167,8 @@ class Qwen3MoeForCausalLM(nn.Module):
             prefix=add_prefix("lm_head", prefix),
             use_attn_tp_group=get_global_server_args().enable_dp_lm_head,
         )
+        if get_global_server_args().enable_fp32_lm_head:
+            self.lm_head = self.lm_head.float()
         self.logits_processor = LogitsProcessor(config)
         self.capture_aux_hidden_states = False
 
@@ -989,6 +1219,16 @@ class Qwen3MoeForCausalLM(nn.Module):
                 forward_batch.hidden_states = self.model.embed_tokens(input_ids)
             else:
                 forward_batch.hidden_states = input_embeds
+            
+            # DEBUG: Embedding output (input to first layer)
+            if os.environ.get("SLIME_DEBUG_ATTN", "0") == "1":
+                tp_rank = get_tensor_model_parallel_rank()
+                tp_size = get_tensor_model_parallel_world_size()
+                pos = 0
+                prefix = f"[qwen3_moe.py][SGLang EMBEDDING][TP {tp_rank}/{tp_size}]"
+                logger.info(f"{prefix} Embedding output (first layer input)[{pos},:5]: {forward_batch.hidden_states[pos, :5].tolist()}")
+                logger.info(f"{prefix} Embedding output sum: {forward_batch.hidden_states[pos].float().sum().item():.6f}")
+                logger.info(f"{prefix} Embedding output shape: {forward_batch.hidden_states.shape}")
 
         # decoder layer
         for i in range(start, end):
diff --git a/python/sglang/srt/server_args.py b/python/sglang/srt/server_args.py
index 72db298..c5aaa28 100644
--- a/python/sglang/srt/server_args.py
+++ b/python/sglang/srt/server_args.py
@@ -164,7 +164,7 @@ NSA_CHOICES = [
 
 RADIX_EVICTION_POLICY_CHOICES = ["lru", "lfu"]
 
-RL_ON_POLICY_TARGET_CHOICES = ["fsdp"]
+RL_ON_POLICY_TARGET_CHOICES = ["fsdp", "fsdp_tp"]
 
 MOE_RUNNER_BACKEND_CHOICES = [
     "auto",
@@ -285,6 +285,7 @@ class ServerArgs:
     quantization_param_path: Optional[str] = None
     kv_cache_dtype: str = "auto"
     enable_fp32_lm_head: bool = False
+    enable_fp32_route: bool = False
     modelopt_quant: Optional[Union[str, Dict]] = None
     modelopt_checkpoint_restore_path: Optional[str] = None
     modelopt_checkpoint_save_path: Optional[str] = None
@@ -2708,6 +2709,11 @@ class ServerArgs:
             action="store_true",
             help="If set, the LM head outputs (logits) are in FP32.",
         )
+        parser.add_argument(
+            "--enable-fp32-route",
+            action="store_true",
+            help="If set, the route(moe) are in FP32.",
+        )
         parser.add_argument(
             "--modelopt-quant",
             type=str,
